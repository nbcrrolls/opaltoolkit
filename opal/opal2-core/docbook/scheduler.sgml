<chapter id="scheduler" xreflabel="Scheduler Support Using Job Managers">
<title>Scheduler Support Using Job Managers</title>

<para>In this chapter, we describe how to configure Opal so that it can
submit jobs to an external scheduler, using the various job managers
provided. We also provide a brief introduction on how to write your own job
manager, if need be.</para>

<para>The prerequisite to this section is that you have a scheduler such as
Condor or SGE installed on your compute cluster. Access to schedulers is
provided in a number of ways - in particular, via the DRMAA API, and via 
the various scheduler plugins. Starting with release 2.1, we support Condor 
natively without using DRMAA or Globus. In release 2.3, we introduced 
direct support for TORQUE/PBS. Please consult the appropriate documentation 
for the installation of these scheduler tools.</para>

<section id="drmaa-scheduler" xreflabel="DRMAA Setup">
<title>Using DRMAA</title>

<orderedlist>
<listitem><para>Ensure that your scheduler supports job submission via the DRMAA API.
Also ensure that <emphasis role="italics">libdrmaa.so</emphasis> is in your library path (by setting
 the LD_LIBRARY_PATH environment variable). We have only tested job
 submissions to SGE 6.x.</para></listitem>

<listitem><para>Set the following properties inside the opal.properties
file: <filename>opal.jobmanager</filename> to
<filename>edu.sdsc.nbcr.opal.manager.DRMAAJobManager</filename>, and
<filename>drmaa.pe</filename> to the name of the parallel environment (PE)
to be used to submit parallel jobs. You can ignore drmaa.pe if you do not
plan on supporting parallel jobs. You can optionally set a DRMAA queue for
job submission by setting the <filename>drmaa.queue</filename> property.
</para>

<para>Note that the <filename>drmaa.pe</filename> and the
<filename>drmaa.queue</filename> can also be overridden on a
per-application basis within the application configuration file.</para>

</listitem>

<listitem><para>Reinstall Opal by running the following command:
<screen>
    ant install
</screen>
</para>

</listitem>

<listitem><para>Restart Tomcat for the changes to take effect.</para></listitem>

<listitem><para>Note that we do not stage input and output files from the
Opal server to the submit host if DRMAA is being used; hence, the machines
should be on a shared file system for the DRMAA job manager to work
correctly.</para> 

<para>Also note that DRMAA support will not work correctly if you have
another version of the drmaa.jar inside Tomcat's common/lib or server/lib
directories, since that will be loaded first by Tomcat's class
loader.</para></listitem>
</orderedlist>
</section>

<section id="condor-scheduler" xreflabel="Condor Setup">
<title>Using Condor</title>

<orderedlist>
<listitem><para>Ensure that you have a working Condor pool by following the
Condor <ulink type="http"
url="http://www.cs.wisc.edu/condor/manual/v7.0.5/">manual</ulink>. We have
tested with version 7.0.5, but we expect that it will work with most recent
Condor versions. In particular, verify that you can submit and monitor jobs
from the command-line with commands such as
<filename>condor_submit</filename>, <filename>condor_status</filename>,
etc., and that these commands are in the Opal user's
PATH.</para></listitem>

<listitem><para>Set the following properties inside the opal.properties
file: <filename>opal.jobmanager</filename> to
<filename>edu.sdsc.nbcr.opal.manager.CondorJobManager</filename>, and
<filename>mpi.script</filename> to the script used by Condor to submit
parallel jobs. You can ignore mpi.script if you do not plan on supporting
parallel jobs. </para></listitem>

<listitem><para>Reinstall Opal by running the following command:
<screen>
    ant install
</screen>
</para>
</listitem>

<listitem><para>Restart Tomcat for the changes to take effect.</para></listitem>

<listitem><para>Note that we have not tested advanced Condor features such
as flocking and Condor-G.</para></listitem>
</orderedlist>

</section>

<section id="pbs-scheduler" xreflabel="TORQUE/PBS Setup">
<title>Using TORQUE/PBS</title>

<orderedlist>
<listitem><para>Ensure that you have a working TORQUE/PBS installation, by following the instructions on the TORQUE <ulink type="http" url="http://www.clusterresources.com/products/torque-resource-manager.php">website</ulink>. In particular, verify that you can submit and monitor jobs from the command-line with commands such as <filename>qsub</filename> and <filename>qstat</filename>. Note that we have only tested with version 2.3.0 of TORQUE.</para></listitem>

<listitem><para>Inside the opal.properties, set the
<filename>opal.jobmanager</filename> to
<filename>edu.sdsc.nbcr.opal.manager.PBSJobManager</filename>.</para></listitem>

<listitem><para>Reinstall Opal by running the following command:
<screen>
    ant install
</screen>
</para>
</listitem>

<listitem><para>Make sure that you all the PBS binaries such as
<filename>qsub</filename> and <filename>qstat</filename> in your
PATH.</para></listitem>

<listitem><para>Restart Tomcat for the changes to take effect.</para></listitem>

</orderedlist>

</section>


<section id="meta-service-scheduler" xreflabel="Meta Service Scheduler Setup">
<title>Using Meta Service</title>

<para>
The Opal meta service plugin can be used to send jobs to various remote 
Opal services.  You can define several remote hosts for a particular
web service, and the web service will run on a random host chosen from this 
set of remote hosts.  In a future Opal release, we may enhance the 
meta scheduling algorithm.
</para>

<para>
The &lt;metaServiceConfig&gt; tag in the application configuration file
is used to define the location of the meta service configuration file
for the particular service.  For example, 
<screen>
&lt;metaServiceConfig&gt;/home/opaluser/meta/pdb2pqr.txt&lt;/metaServiceConfig&gt;
</screen>
</para>

<para>
The meta service configuration file contains one or more lines, where each
line contains a remote Opal service URL followed by a space and then the 
number of processors on that remote Opal service.  Please use 1 as the 
number of processors for serial services.  The sample file below defines
the remote hosts for the Pdb2pqr meta service.
<screen>
http://kryptonite.nbcr.net/opal2/services/pdb2pqr_1.7 1
http://ws.nbcr.net/opal2/services/Pdb2pqrOpalService 1
</screen>
</para>

</section>

<section id="jobmanager-howto" xreflabel="Writing Your Own Job Manager">
<title>Writing Your Own Job Manager</title>

<para>If the job managers provided by the Opal toolkit are not sufficient
for your purposes, you can write your own job managers to submit jobs to
your favorite scheduler. This section presents a brief tutorial on how to
do so.</para>

<para>To write your own Opal job manager, you must implement the
<filename>edu.sdsc.nbcr.opal.manager.OpalJobManager</filename> interface.
One job manager is instantiated per job instance - i.e. for every run of an
application, a new job manager is created. The OpalJobManager interface
that 6 methods that must be implemented:</para>

<orderedlist>

<listitem><para>The <filename>initialize</filename> method initializes the
job manager, by setting a list of properties (key/value pairs), application
configuration, and an optional handle. All job manager specific properties
should be put inside <filename>$OPAL_HOME/etc/opal.properties</filename>.
Opal will parse all the properties from opal.properties and make them
available to the job manager.</para>

<screen>
    /**
     * @param props the properties file containing the value to configure this plugin
     * @param config the opal configuration for this application
     * @param handle manager specific handle to bind to, if this is a resumption. 
     *               NULL,if this manager is being initialized for the first time.
     * 
     * @throws JobManagerException if there is an error during initialization
     */
    public void initialize(Properties props,
			   AppConfigType config,
			   String handle)
	throws JobManagerException;
</screen>
</listitem>

<listitem><para>The <filename>destroyJobManager</filename> is for cleanup
when the job manager is destroyed - all resources held should be freed
here.</para>

<screen>
    /**
     * @throws JobManagerException if there is an error during destruction
     */
    public void destroyJobManager()
	throws JobManagerException;
</screen>
</listitem>

<listitem><para>The <filename>launchJob</filename> method is for launching
a job with the given arguments. The input files are already staged in by
the service implementation, and the job manager implementation can assume
that they are already in the right location.</para>

<screen>
    /**
     * Launch a job with the given arguments. 
     *
     * @param argList a string containing the command line used to launch the application
     * @param numproc the number of processors requested. Null, if it is a serial job
     * @param workingDir String representing the working dir of this job on the local system
     * 
     * @return a plugin specific job handle to be persisted by the service implementation
     * @throws JobManagerException if there is an error during job launch
     */
    public String launchJob(String argList, 
			    Integer numproc, 
			    String workingDir)
	throws JobManagerException;
</screen>
</listitem>

<listitem><para>The <filename>waitForActivation</filename> method should
block until the job has begun execution. Opal uses this information to
collect job statistics.</para>

<screen>
    /**
     * @return status for this job after blocking
     * @throws JobManagerException if there is an error while waiting for the job to be ACTIVE
     */
    public StatusOutputType waitForActivation() 
	throws JobManagerException;
</screen>
</listitem>

<listitem><para>The <filename>waitForCompletion</filename> method should
block until the application has finished execution.</para>

<screen>
    /**
     * @return final job status
     * @throws JobManagerException if there is an error while waiting for the job to finish
     */
    public StatusOutputType waitForCompletion() 
	throws JobManagerException;
</screen>
</listitem>

<listitem><para>The <filename>destroyJob</filename> method should kill an
executing job.</para>

<screen>
    /**
     * @return final job status
     * @throws JobManagerException if there is an error during job destruction
     */
    public StatusOutputType destroyJob()
	throws JobManagerException;
</screen>
</listitem>
</orderedlist>

<para>More information about the Java classes can be obtained from the Javadocs, which you can generate from $OPAL_HOME as follows:</para>

<screen>
    ant api-docs
</screen>

<para>This will generate documentation of the Opal API, which will be
available in HTML form at
<filename>$OPAL_HOME/docs/api/index.html</filename>.</para>

<para>We recommend that you implement your particular job manager inside
the directory
<filename>$OPAL_HOME/src/edu/sdsc/nbcr/opal/manager</filename>. There you
will find other job managers that are available by default - you might want
to look at the <filename>ForkJobManager</filename> as an example. You can
compile your job manager with the rest of Opal, and install it within
Tomcat by running the following commands:</para>

<screen>
    ant compile
    ant install
</screen>
</section>
</chapter>

